{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Esteban_Garcia_Tarea1-Parte2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdtaAwa8XzNA",
        "colab_type": "text"
      },
      "source": [
        "# Estadística para Ciencia de los Datos\n",
        "# Esteban Garcia Solis\n",
        "# Tarea #1 - Semana #2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yosWpoT7AxRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np;\n",
        "import matplotlib.pyplot as plt;\n",
        "from scipy.stats import norm\n",
        "\n",
        "def printTable(table):\n",
        "  col_width = max(len(word) for row in table for word in row) + 2  # padding\n",
        "  for row in table:\n",
        "      print(\"\".join(word.ljust(col_width) for word in row))\n",
        "  print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chgbdVm7TbL-",
        "colab_type": "text"
      },
      "source": [
        "## Parte 2\n",
        "\n",
        "Envíe un notebook de colab con el código correspondiente a la solución de los siguientes ejercicios a través de TEC Digital a más tardar el domingo 15 de septiembre a las 10 PM. No se aceptarán entregas tardías. Se espera que el código pueda ejecutarse con visualizaciones apropiadas, sino no se asignará puntaje.\n",
        "\n",
        "1. Muestreo de estaturas. Los estudiantes deberán programar dos funciones para crear muestras de $N$ personas (observaciones) con una sola variable aleatoria: estatura. Para efectos prácticos, ambas funciones pueden retornar una simple lista con valores numéricos que representan la estatura en centímetros de diferentes personas. Para ambas funciones deberán mostrarse ejemplos de creación de muestras con al menos 100 observaciones y mostrarlas en un histograma. La cantidad de cubetas deberá limitarse a un máximo de 9. Las funciones a programar serán las siguientes:\n",
        " * **Muestreo Uniforme**. Además de recibir la cantidad de observaciones a generar $N$, recibirá la estatura mínima y máxima  por parámetro. Por ejemplo, si se pide una distribución uniforme entre 150 y 168, las estaturas entre ese rango deberán ser igual de probables de muestrear. (5 puntos)\n",
        "  * **Muestreo Normal**. Además de recibir la cantidad de observaciones a generar $N$, recibirá la media y desviación estándar por parámetro. De esta forma, la función generará $N$ observaciones provenientes de una distribución Gaussiana con la media y desviación estándar recibidas. (5 puntos)\n",
        "  \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILjLefNJYSrw",
        "colab_type": "code",
        "outputId": "581a75c7-d27f-4a3e-b015-a26648522e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "def uniformSample(min, max, n):\n",
        "  return np.random.uniform(min, max, n)\n",
        "\n",
        "def normalSample(mu, sigma, n):\n",
        "  return np.random.normal(mu, sigma, n)\n",
        "\n",
        "def plotHistogram(data, bins, title):\n",
        "  if bins > 9:\n",
        "    print(\"invalid number of bins: {}\".format(bins))\n",
        "  else:\n",
        "    plt.hist(data, bins)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def test(min, max, mu, sigma, n, bins):\n",
        "  uniform = uniformSample(min, max, n)\n",
        "  normal = normalSample(mu, sigma, n)\n",
        "  plotHistogram(uniform, bins, \"Uniform distribution test\")\n",
        "  plotHistogram(normal, bins, \"Normal distribution test\")\n",
        "\n",
        "test(min=120, max=200, mu=160, sigma=20, n=100, bins=9)\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njjDQJakjDHRJ6ggDXZI64v8D832Z9Ga3LeEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y66h0V-qKfIj",
        "colab_type": "text"
      },
      "source": [
        "2. **Evaluación de la función de verosimilitud normal**. Deberán proveer una función que reciba una de las **muestras** del punto 1 y evalúe la probabilidad que esa muestra provenga de una distribución normal con parámetros $\\mu$ y $\\sigma$ (que deberán ser enviados a la función). Deberán mostrar ejemplos obtenidos bajo ambos esquemas de muestreo. Por ejemplo, si se crea una muestra normal centrada en $\\mu_1=177$ con $\\sigma_1=1$ y evaluamos la verosimilitud para $\\mu=176,\\sigma=3$ podría darnos una probabilidad alta. En contraposición, al crear una muestra uniforme entre $170$ y $180$ y evaluarla para esos mismos parámetros de verosimilitud, se esperaría que sea menos probable. Todo lo anterior debe reflejarse con ejemplos que muestren el correcto funcionamiento (10 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDopAfZbKp2c",
        "colab_type": "code",
        "outputId": "e05f3cee-f644-4a32-f348-a3b1215d3bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def normalProbabilityDensity(h, mu, sigma):\n",
        "  return np.prod(norm.pdf(h, mu, sigma))\n",
        "\n",
        "def testLikelihood(min, max, mu, sigma, n, muL, sigmaL, table):\n",
        "  hNormal  = normalSample(mu, sigma, n)\n",
        "  hUniform = uniformSample(min, max, n)\n",
        "\n",
        "  likelihoodNormal  = normalProbabilityDensity(hNormal, muL, sigmaL) \n",
        "  likelihoodUniform = normalProbabilityDensity(hUniform, muL, sigmaL)\n",
        "\n",
        "  table.append([\"Normal (mu:{}, sigma:{})\".format(mu, sigma), str(n), str(muL), str(sigmaL), str(likelihoodNormal)])\n",
        "  table.append([\"Uniform (min:{}, max:{})\".format(min, max), str(n), str(muL), str(sigmaL), str(likelihoodUniform)])\n",
        "\n",
        "  return table\n",
        "\n",
        "result = [[\"Distribution\", \"n\", \"mu\", \"sigma\", \"Likelihood\"]]\n",
        "result = testLikelihood(min = 170, max = 180, mu = 177, sigma = 1,  n = 10, muL = 176, sigmaL = 3, table = result)\n",
        "result = testLikelihood(min = 155, max = 175, mu = 160, sigma = 10, n = 10, muL = 160, sigmaL = 10, table = result)\n",
        "\n",
        "printTable(result)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution                n                           mu                          sigma                       Likelihood                  \n",
            "Normal (mu:177, sigma:1)    10                          176                         3                           7.024910481796183e-10       \n",
            "Uniform (min:170, max:180)  10                          176                         3                           5.48439996566021e-11        \n",
            "Normal (mu:160, sigma:10)   10                          160                         10                          3.733881783788632e-17       \n",
            "Uniform (min:155, max:175)  10                          160                         10                          4.0533343023996867e-16      \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbUFemCOKrak",
        "colab_type": "text"
      },
      "source": [
        "3. ¿Qué problema ocurre con el cálculo de la función de verosimilitud cuando aumentamos la cantidad de observaciones en varios órdenes de magnitud? y ¿Cual sería una forma de solucionar este problema? Programe una función con la posible solución y anote como comentarios las respuestas a las dos preguntas anteriores. De igual forma muestre un ejemplo de como invocar esta función (10 puntos)\n",
        "\n",
        ">R/ Al incrementar la cantidad de observaciones la multiplicatoria de números pequeños hace que los resultados se aproximen cada vez más a 0. Al punto de obtener un underflow. En la tabla siguiente vemos como con n = 1000 el calculo de la verosimilitud da resultado 0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhBL4O2fKskw",
        "colab_type": "code",
        "outputId": "8618f06f-ed70-4424-c5ec-7d1e270e19ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "result = [[\"Distribution\", \"n\", \"mu\", \"sigma\", \"Likelihood\"]]\n",
        "result = testLikelihood(min = 170, max = 180, mu = 177, sigma = 1,  n = 10, muL = 176, sigmaL = 3, table = result)\n",
        "result = testLikelihood(min = 170, max = 180, mu = 177, sigma = 1,  n = 100, muL = 176, sigmaL = 3, table = result)\n",
        "result = testLikelihood(min = 170, max = 180, mu = 177, sigma = 1,  n = 1000, muL = 176, sigmaL = 3, table = result)\n",
        "printTable(result)\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution                n                           mu                          sigma                       Likelihood                  \n",
            "Normal (mu:177, sigma:1)    10                          176                         3                           6.896664886716653e-10       \n",
            "Uniform (min:170, max:180)  10                          176                         3                           1.894805154266882e-11       \n",
            "Normal (mu:177, sigma:1)    100                         176                         3                           6.446858287122697e-93       \n",
            "Uniform (min:170, max:180)  100                         176                         3                           1.1234097039416466e-109     \n",
            "Normal (mu:177, sigma:1)    1000                        176                         3                           0.0                         \n",
            "Uniform (min:170, max:180)  1000                        176                         3                           0.0                         \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19xok9EnyhfX",
        "colab_type": "text"
      },
      "source": [
        ">Para solucionar el problema del underflow se puede utilizar la propiedad del logaritmo natural:  \n",
        ">>$\\ln\\left(x\\cdot y\\right)=\\ln\\left(x\\right)+\\ln\\left(y\\right)$\n",
        "\n",
        ">Asi modificamos la función normalProbabilityDensity para corregir el problema, en la tabla mostrada abajo podemos ver que ya no hay underflow y aún logramos tener una noción de que probabilidad es más alta en comparación con las demás."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9iCezZKyh_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "78df8561-5fc1-4338-9052-ea05f7dfff7a"
      },
      "source": [
        "def normalProbabilityDensityLn(h, mu, sigma):\n",
        "  return np.sum(np.log(norm.pdf(h, mu, sigma)))\n",
        "\n",
        "def testLikelihoodLn(min, max, mu, sigma, n, muL, sigmaL, table):\n",
        "  hNormal  = normalSample(mu, sigma, n)\n",
        "  hUniform = uniformSample(min, max, n)\n",
        "\n",
        "  likelihoodNormal  = normalProbabilityDensityLn(hNormal, muL, sigmaL)\n",
        "  likelihoodUniform = normalProbabilityDensityLn(hUniform, muL, sigmaL)\n",
        "\n",
        "  table.append([\"Normal (mu:{}, sigma:{})\".format(mu, sigma), str(n), str(muL), str(sigmaL), str(likelihoodNormal)])\n",
        "  table.append([\"Uniform (min:{}, max:{})\".format(min, max),  str(n), str(muL), str(sigmaL), str(likelihoodUniform)])\n",
        "\n",
        "  return table\n",
        "\n",
        "result = [[\"Distribution\", \"n\", \"mu\", \"sigma\", \"Ln(Likelihood)\"]]\n",
        "result = testLikelihoodLn(min = 170, max = 180, mu = 177, sigma = 1,  n = 10, muL = 176, sigmaL = 3, table = result)\n",
        "result = testLikelihoodLn(min = 170, max = 180, mu = 177, sigma = 1,  n = 100, muL = 176, sigmaL = 3, table = result)\n",
        "result = testLikelihoodLn(min = 170, max = 180, mu = 177, sigma = 1,  n = 1000, muL = 176, sigmaL = 3, table = result)\n",
        "\n",
        "printTable(result)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distribution                n                           mu                          sigma                       Ln(Likelihood)              \n",
            "Normal (mu:177, sigma:1)    10                          176                         3                           -20.81688072521609          \n",
            "Uniform (min:170, max:180)  10                          176                         3                           -26.41555530753203          \n",
            "Normal (mu:177, sigma:1)    100                         176                         3                           -212.63911350636337         \n",
            "Uniform (min:170, max:180)  100                         176                         3                           -246.23229906256267         \n",
            "Normal (mu:177, sigma:1)    1000                        176                         3                           -2123.706039537701          \n",
            "Uniform (min:170, max:180)  1000                        176                         3                           -2489.4664129883367         \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58OTKb0NKta4",
        "colab_type": "text"
      },
      "source": [
        "4. Implemente una función para determinar los valores óptimos para maximizar la función de verosimilitud normal, según teoría vista en clase. Suponga que la cantidad de observaciones (N) siempre es alta. Igualmente se espera que se provean ejemplos en el código para mostrar el correcto funcionamiento (10 puntos)\n",
        "\n",
        ">nota: El parámetro ddof permite variar el factor de normalizacion: $\\frac{1}{n-ddof}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXm8qktgK-30",
        "colab_type": "code",
        "outputId": "814afbdc-9996-41ac-8412-483f96bf86c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def maxLikelihoodEstimation(sample, ddof=0):\n",
        "  return (np.mean(sample), np.std(sample, ddof=ddof))\n",
        "\n",
        "hNormal  = normalSample(mu = 160, sigma = 20, n= 50)\n",
        "\n",
        "print(maxLikelihoodEstimation(hNormal))\n"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(154.18084270177496, 17.83338690387705)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk6oWkOwK_TX",
        "colab_type": "text"
      },
      "source": [
        "5. Genere 10000 muestras de 50 observaciones cada una  provenientes de una distribución normal con $\\mu=170$ y $\\sigma=1$. Calcule el valor óptimo de la varianza para maximizar la función de verosimilitud normal de cada muestra (estimador de la varianza sesgado) y luego obtenga el valor esperado de la varianza (promedio sobre las 10000 muestras). Compare este valor esperado con el valor  de varianza usado para generar las muestras ($\\sigma^{2}=1$)  . Ejecute varias veces su código y responda ¿El valor esperado de la varianza aproxima de manera correcta la varianza original  de la distribución o es necesario hacer alguna corrección en este caso para el cálculo del valor óptimo de la varianza? Justifique su respuesta en ambos casos y explique cual sería la corrección en caso afirmativo (10 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSU7VZjQK_vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateNormalSamples(mu, sigma, n, r):\n",
        "  samples = []\n",
        "  for i in range(r):\n",
        "    samples.append(normalSample(mu, sigma, n))\n",
        "  return samples\n",
        "\n",
        "def maxLikelihoodEstimations(samples, ddof=0):\n",
        "  estimations = []\n",
        "  for i in range(len(samples)):\n",
        "    estimations.append(maxLikelihoodEstimation(samples[i], ddof))\n",
        "  return estimations\n",
        "\n",
        "def testVarianceEstimation(mu, sigma, n, r, ddof, tests):\n",
        "  table = [[\"Dist. Var.\", \"Avg. Var.\", \"Difference\"]]\n",
        "  for i in range(tests):\n",
        "    variance = sigma * sigma\n",
        "    normalSamples = generateNormalSamples(mu=170, sigma=1, n=n, r=r)\n",
        "    estimations = np.array(maxLikelihoodEstimations(normalSamples, ddof))\n",
        "    expectedVariance = np.sum(estimations[:,1] * estimations[:,1]) / r\n",
        "    table.append([str(variance), str(expectedVariance), str(abs(variance - expectedVariance))])\n",
        "  print(\"Samples: \" + str(r))\n",
        "  print(\"Observation per sample: \" + str(n))\n",
        "  print(\"\")\n",
        "  printTable(table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bQMg67rImc3",
        "colab_type": "text"
      },
      "source": [
        ">Al usar el estimador de varianza sesgado se puede ver que se aproxima bastante al valor de la varianza ($\\sigma^{2}=1$), sin embargo, al reducir la cantidad de observaciones por muestra se ve que la estimación deja de ser tan acertada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpfgy2L8InOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "51b524aa-0ec9-4bfc-ab40-1a663674af2a"
      },
      "source": [
        "\"\"\" Using biased estimator \"\"\"\n",
        "testVarianceEstimation(170, 1, 50, 10000, 0, 10)\n",
        "\n",
        "\"\"\" Using biased estimator \"\"\"\n",
        "testVarianceEstimation(170, 1, 10, 10000, 0, 10)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples: 10000\n",
            "Observation per sample: 50\n",
            "\n",
            "Dist. Var.            Avg. Var.             Difference            \n",
            "1                     0.9799138243702031    0.020086175629796865  \n",
            "1                     0.9841526004210417    0.01584739957895831   \n",
            "1                     0.9801230007220374    0.019876999277962604  \n",
            "1                     0.9803967023156772    0.019603297684322785  \n",
            "1                     0.9816207685556539    0.018379231444346056  \n",
            "1                     0.9794516330032129    0.020548366996787082  \n",
            "1                     0.9791951053665429    0.02080489463345714   \n",
            "1                     0.9834128983799797    0.016587101620020306  \n",
            "1                     0.9832713653263834    0.016728634673616627  \n",
            "1                     0.9810270159056274    0.018972984094372647  \n",
            "\n",
            "Samples: 10000\n",
            "Observation per sample: 10\n",
            "\n",
            "Dist. Var.           Avg. Var.            Difference           \n",
            "1                    0.8984479284809197   0.1015520715190803   \n",
            "1                    0.9067930442962053   0.09320695570379467  \n",
            "1                    0.9004141613592951   0.09958583864070492  \n",
            "1                    0.9033401309613215   0.09665986903867851  \n",
            "1                    0.9079686738242632   0.09203132617573684  \n",
            "1                    0.8996371953576249   0.10036280464237513  \n",
            "1                    0.9066711159984002   0.09332888400159978  \n",
            "1                    0.9010755763448848   0.09892442365511522  \n",
            "1                    0.8983621448448627   0.10163785515513735  \n",
            "1                    0.9023690193854796   0.09763098061452036  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfrkRpksIvd1",
        "colab_type": "text"
      },
      "source": [
        ">Para solucionar el problema utilizamos el estimador de varianza sesgado y vemos como la Estimación se mantiene incluso al utilizar menos observaciones por muestra:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY98td6eIv28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "a2b09b73-1fcd-46f7-d434-7d888808d9a5"
      },
      "source": [
        "\"\"\" Using non biased estimator \"\"\"\n",
        "testVarianceEstimation(170, 1, 50, 10000, 1, 10)\n",
        "\n",
        "\"\"\" Using non biased estimator \"\"\"\n",
        "testVarianceEstimation(170, 1, 10, 10000, 1, 10)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples: 10000\n",
            "Observation per sample: 50\n",
            "\n",
            "Dist. Var.              Avg. Var.               Difference              \n",
            "1                       1.000903318671411       0.0009033186714109132   \n",
            "1                       1.0014510568225665      0.001451056822566521    \n",
            "1                       1.000126421794978       0.0001264217949779045   \n",
            "1                       1.0007742642953505      0.0007742642953505463   \n",
            "1                       0.9952215980637613      0.004778401936238685    \n",
            "1                       0.9981052108511822      0.0018947891488177993   \n",
            "1                       0.9969156875101493      0.003084312489850749    \n",
            "1                       1.000370979771648       0.00037097977164801677  \n",
            "1                       1.002574740169263       0.002574740169263068    \n",
            "1                       0.997607468502425       0.0023925314975750123   \n",
            "\n",
            "Samples: 10000\n",
            "Observation per sample: 10\n",
            "\n",
            "Dist. Var.             Avg. Var.              Difference             \n",
            "1                      1.0129155001116852     0.012915500111685185   \n",
            "1                      1.0000855405245057     8.55405245057117e-05   \n",
            "1                      1.0088634121990137     0.008863412199013654   \n",
            "1                      1.0022550608846952     0.0022550608846951814  \n",
            "1                      1.0035648698252895     0.003564869825289474   \n",
            "1                      1.0008124423956561     0.0008124423956561433  \n",
            "1                      0.9956467009672336     0.004353299032766378   \n",
            "1                      1.0048178129437824     0.0048178129437823625  \n",
            "1                      0.9990535168668272     0.0009464831331728041  \n",
            "1                      0.9986394922872163     0.0013605077127837317  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
