{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea_4_Esteban Garcia.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKuYaD0VkaqJ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "\n",
        "data = {'Ob1':[1.65, 1.70, 1.40, 2.10],\n",
        "        'Ob2':[1.72, 1.85, 1.75, 1.95],\n",
        "        'Ob3':[1.50, 1.46, 1.38, 1.65],\n",
        "        'Ob4':[1.37, 1.46, 1.38, 1.65],\n",
        "        'Ob5':[1.60, 1.80, 1.55, 1.88]\n",
        "        }\n",
        " \n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "def yiDot(df, i):\n",
        "  return df.iloc[i].sum()\n",
        "\n",
        "def yiDotMean(df, i):\n",
        "  return yiDot(df, i) / len(df.iloc[i])\n",
        "\n",
        "def yDotDot(df):\n",
        "  return df.sum().sum()\n",
        "\n",
        "def yDotDotMean(df):\n",
        "  return yDotDot(df) / df.size\n",
        "\n",
        "def SSError(df):\n",
        "  sum = 0\n",
        "  (rows, cols) = df.shape\n",
        "  \n",
        "  for i in range(rows):\n",
        "    yiDotMean_val = yiDotMean(df, i)\n",
        "    for j in range(cols):\n",
        "      sum += (df.iloc[i, j] - yiDotMean_val) ** 2\n",
        "  return sum\n",
        "\n",
        "def SSTratamiento(df):\n",
        "  sum = 0\n",
        "  (rows, cols) = df.shape\n",
        "  yDotDotMean_val = yDotDotMean(df)\n",
        "  \n",
        "  for i in range(rows):\n",
        "    sum += (yiDotMean(df, i) - yDotDotMean_val) ** 2\n",
        "  return sum * cols\n",
        "\n",
        "def SST(df):\n",
        "  return SSError(df) + SSTratamiento(df)\n",
        "  \n",
        "def MSTratamiento(df):\n",
        "  (rows, cols) = df.shape\n",
        "  return(SSTratamiento(df) / (rows - 1))\n",
        "\n",
        "def MSError(df):\n",
        "  (rows, cols) = df.shape\n",
        "  return SSError(df) / (rows * (cols - 1))\n",
        "\n",
        "def F0(df):\n",
        "  return MSTratamiento(df) / MSError(df)\n",
        "\n",
        "def printTable(table):\n",
        "  col_width = max(len(word) for row in table for word in row) + 2  # padding\n",
        "  for row in table:\n",
        "      print(\"\".join(word.ljust(col_width) for word in row))\n",
        "  print(\"\")\n",
        "\n",
        "def ANOVA(df):\n",
        "  (rows, cols) = df.shape\n",
        "\n",
        "  table = [[\"Source of variation\", \"Sum of squares\", \"Degrees of freedom\", \"Mean Square\", \"F0\"],\n",
        "           [\"Treatments\", str(SSTratamiento(df)), str(rows - 1), str(MSTratamiento(df)), str(F0(df))],\n",
        "           [\"Error\", str(SSError(df)), str(rows*(cols - 1)), str(MSError(df)), \"\"],\n",
        "           [\"Total\", str(SST(df)), str(rows*cols - 1), \"\", \"\"]]\n",
        "\n",
        "  printTable(table)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdtaAwa8XzNA",
        "colab_type": "text"
      },
      "source": [
        "# Estadística para Ciencia de los Datos\n",
        "# Tarea #4\n",
        "## Esteban García Solís\n",
        "\n",
        "## Parte 1\n",
        "\n",
        "Cuatro plantas químicas, que producen los mismos productos y son propiedad de la misma compañía, \n",
        "descargan aguas residuales en arroyos en la cercanía donde se encuentran ubicadas. Para vigilar la magnitud de la contaminación creada por las aguas residuales y para determinar si esto difiere de una planta a otra, la compañía recolectó aleatoriamente  cinco muestras (observaciones) de desechos líquidos de cada planta. Cada observación tomada indica la cantidad de libras por galón de desechos. Los datos se presentan en la siguiente tabla:\n",
        "\n",
        "|Planta | Ob. 1 | Ob. 2   | Ob. 3   | Ob. 4   | Ob. 5   |\n",
        "|--- | --- |    |    |    |    | \n",
        "|**A**|1.65|1.72|1.50|1.37|1.60\n",
        "|**B**|1.70|1.85|1.46|1.46|1.80\n",
        "|**C**|1.40|1.75|1.38|1.38|1.55\n",
        "|**D**|2.10|1.95|1.65|1.65|1.88\n",
        "\n",
        "¿La información aporta suficiente evidencia para indicar una diferencia en el peso medio de las aguas residuales por galón descargadas de las cuatro plantas? Pruebe usando $\\alpha =0.05$ (70 puntos)\n",
        "\n",
        "R/ Se desea probar que el peso medio de las aguas residuales es igual para las plantas A, B, C y D\n",
        "\n",
        "1.   El párametro de interés es $\\mu$\n",
        "2.   $H_{0}:\\mu_{1}=\\mu_{2}=\\mu_{3}=\\mu_{4}$\n",
        "3.   $H_{1}: \\mu_{i}\\neq\\mu_{j} \\space \\text{para al menos un par}(i,j)$\n",
        "4.   Nivel de significancia $\\alpha=0.05$\n",
        "5.   Estadístico de prueba $F_0=\\dfrac{\\textrm{MS}_\\textrm{tratamiento}}{\\textrm{MS}_\\textrm{error}}$ \n",
        "6.   Rechazamos $H_0$ en caso que: $F_0&gt;F_{\\alpha,a-1,N-a}$, $F_0&gt;F_{0.95,3,16}=F_0&gt;3.23887$\n",
        "7.   Cálculamos el estadístico:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpno11Ri2NaZ",
        "colab_type": "code",
        "outputId": "d5b998ae-8932-4978-e2b1-acd3b4c1ed7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from scipy.stats import f\n",
        "print(\"F0.95,3,16= \" + str(f.ppf(0.95,3,16)) + \"\\n\")\n",
        "ANOVA(df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F0.95,3,16= 3.238871517453585\n",
            "\n",
            "Source of variation   Sum of squares        Degrees of freedom    Mean Square           F0                    \n",
            "Treatments            0.34860000000000047   3                     0.11620000000000015   3.9675629534784496    \n",
            "Error                 0.46860000000000024   16                    0.029287500000000015                        \n",
            "Total                 0.8172000000000007    19                                                                \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U17HscpVdsWi",
        "colab_type": "text"
      },
      "source": [
        "8.   $3.9675&gt;3.23887$ Por lo tanto se rechaza $H_0$ con un nivel de significancia de 0.05, al menos una de las plantas difiere en el peso medio de desechos en las aguas residuales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv6ESWD9kiyb",
        "colab_type": "text"
      },
      "source": [
        "## Parte 2\n",
        "\n",
        "Un problema recurrente en ciencia de los datos es qué hacer con datos faltantes (*missing values*). Al proceso a través del cuál solucionamos este problema se le llama *imputación de datos* o tratamiento de valores inválidos. Se recomienda cuando la cantidad de datos faltantes es poca.\n",
        "\n",
        "- Investigue al menos tres estrategias de imputación de datos. Describa en que consiste cada una y en que casos conviene usar cada una. (30 puntos)\n",
        "\n",
        "##Imputación usando métricas de tendencia central \n",
        "Se calcula la media, mediana o la moda usando los datos disponibles en la columna y se usa dicho valor para completar los datos faltantes.\n",
        "\n",
        "*Ventajas:*\n",
        "-\tFunciona bien con conjuntos de datos numéricos pequeños (usando media o mediana)\n",
        "-\tEs una solución rápida de implementar \n",
        "-\tFunciona para valores categóricos (usando la moda)\n",
        "\n",
        "*Desventajas:*\n",
        "-\tReduce la variabilidad de los datos\n",
        "-\tPuede generar un sesgo en los datos\n",
        "-\tNo funciona en datos categóricos\n",
        "-\tNo contempla la correlación entre características \n",
        "\n",
        "##Sustitución/recuperación\n",
        "Tratar de recuperar el valor faltante o remplazar la muestra con una nueva que no es parte del conjunto de datos. Esta opcion es viable cuando hay acceso a la fuente de los datos.\n",
        "\n",
        "*Ventajas:*\n",
        "-\tNo introduce sesgos ni alteraciones al conjunto de datos.\n",
        "\n",
        "*Desventajas:*\n",
        "-\tNo siempre va a ser posible recuperar la información ni obtener una nueva muestra del caso en estudio.\n",
        "-\tSi los datos faltantes son muchos puede resultar impráctico.\n",
        "\n",
        "##Imputación KNN\n",
        "El algoritmo usa \"similitud de características\" para predecir los valores faltantes en el conjunto de datos. Esto significa que al dato faltante se le asigna un valor en función del parecido que tenga a otros puntos en el conjunto de entrenamiento. Para este método se define una cantidad “k” de vecinos que son seleccionados en base a una métrica de distancia. Luego los valores de estos vecinos son promediados para usar como valor estimado para la imputación\n",
        "\n",
        "*Ventajas:*\n",
        "-\tPuede ser más preciso que el método de imputación usando métricas de tendencia central\n",
        "\n",
        "*Desventajas:*\n",
        "-\tSu ejecución puede consumir mucho tiempo en conjuntos de datos grandes\n",
        "-\tEs sensible a valores extraños \n",
        "\n",
        "###Referencias\n",
        "*Georgios Drakos, (2018, Jul 31), Handling Missing Values in Machine Learning, Retrieved 2019, Oct 14, from https://towardsdatascience.com/handling-missing-values-in-machine-learning-part-2-222154b4b58e*\n",
        "\n",
        "*Wale Akinfaderin, (2017, Sep 11), Missing Data Conundrum: Exploration and Imputation Techniques, Retrieved 2019, Oct 14, from https://medium.com/ibm-data-science-experience/missing-data-conundrum-exploration-and-imputation-techniques-9f40abe0fd87*\n",
        "\n",
        "*Yohan Obadia, (2017, Jan 31), The use of KNN for missing values, Retrieved 2019, Oct 14, from, https://towardsdatascience.com/the-use-of-knn-for-missing-values-cf33d935c637*\n",
        "\n",
        "*Will Badr, (2019, Jan 5), 6 Different Ways to Compensate for Missing Values In a Dataset, Retrieved 2019, Oct 14, from https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779*\n",
        "\n"
      ]
    }
  ]
}
